{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c63b78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries and configuration loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import json\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_FOLDER = 'judgments'\n",
    "OUTPUT_FOLDER = 'structured_output'\n",
    "\n",
    "print(\"Libraries and configuration loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f4982e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# --- HELPER FUNCTIONS FOR EXTRACTION ---\n",
    "\n",
    "def extract_metadata(full_text):\n",
    "   \n",
    "    metadata = {\n",
    "        'court': 'Not Found', 'case_number': 'Not Found',\n",
    "        'petitioner': 'Not Found', 'respondent': 'Not Found',\n",
    "        'judgment_date': 'Not Found'\n",
    "    }\n",
    "    # (The rest of the function code is the same as before)\n",
    "    court_match = re.search(r\"IN THE (SUPREME COURT OF INDIA|HIGH COURT OF [A-Z ]+)\", full_text, re.IGNORECASE)\n",
    "    if court_match: metadata['court'] = court_match.group(0).strip()\n",
    "    case_no_match = re.search(r\"([A-Z\\.\\s]+\\s?(?:NO|Number)\\.\\s\\d+\\sOF\\s\\d{4})\", full_text, re.IGNORECASE)\n",
    "    if case_no_match: metadata['case_number'] = case_no_match.group(1).strip()\n",
    "    parties_match = re.search(r\"([A-Za-z\\s\\.,&]+)\\s*\\.{3,}\\s*(?:Petitioner|Appellant)\\(s\\)\\s*VERSUS\\s*([A-Za-z\\s\\.,&]+)\\s*\\.{3,}\\s*(?:Respondent)\\(s\\)\", full_text, re.DOTALL | re.IGNORECASE)\n",
    "    if parties_match:\n",
    "        metadata['petitioner'] = parties_match.group(1).strip().replace('\\n', ' ')\n",
    "        metadata['respondent'] = parties_match.group(2).strip().replace('\\n', ' ')\n",
    "    date_match = re.search(r\"(?:Date of judgment|Dated|Decided on):?\\s*(\\d{1,2}[\\.\\-/]\\d{1,2}[\\.\\-/]\\d{4})\", full_text, re.IGNORECASE)\n",
    "    if date_match: metadata['judgment_date'] = date_match.group(1).strip()\n",
    "    return metadata\n",
    "\n",
    "def extract_sections(full_text):\n",
    "    \"\"\"\n",
    "    Extracts key sections like facts, arguments, and ratio.\n",
    "    \"\"\"\n",
    "    # (The function code is the same as before)\n",
    "    extracted_sections = {}\n",
    "    section_markers = {\n",
    "        'facts': [r\"FACTS OF THE CASE\", r\"BRIEF FACTS\", r\"THE FACTUAL MATRIX\", r\"BACKGROUND\"],\n",
    "        'arguments_petitioner': [r\"ARGUMENTS OF THE PETITIONER\", r\"SUBMISSIONS ON BEHALF OF THE PETITIONER\", r\"CONTENTIONS OF THE APPELLANT\"],\n",
    "        'arguments_respondent': [r\"ARGUMENTS OF THE RESPONDENT\", r\"SUBMISSIONS ON BEHALF OF THE RESPONDENT\", r\"CONTENTIONS OF THE RESPONDENT\"],\n",
    "        'ratio': [r\"RATIO DECIDENDI\", r\"REASONING OF THE COURT\", r\"ANALYSIS AND FINDINGS\", r\"COURT'S ANALYSIS\"],\n",
    "        'conclusion': [r\"CONCLUSION\", r\"ORDER\", r\"IN THE RESULT\"]\n",
    "    }\n",
    "    all_markers_pattern = '|'.join([item for sublist in section_markers.values() for item in sublist])\n",
    "    matches = list(re.finditer(all_markers_pattern, full_text, re.IGNORECASE))\n",
    "    if not matches:\n",
    "        extracted_sections['full_text_no_sections_found'] = full_text\n",
    "        return extracted_sections\n",
    "    for i, current_match in enumerate(matches):\n",
    "        section_start_pos = current_match.start()\n",
    "        current_heading = current_match.group(0).upper()\n",
    "        current_section_name = \"unknown_section\"\n",
    "        for name, patterns in section_markers.items():\n",
    "            if any(pattern in current_heading for pattern in patterns):\n",
    "                current_section_name = name\n",
    "                break\n",
    "        section_end_pos = matches[i + 1].start() if i + 1 < len(matches) else len(full_text)\n",
    "        section_text = full_text[section_start_pos:section_end_pos].strip()\n",
    "        extracted_sections[current_section_name] = section_text\n",
    "    return extracted_sections\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a7450d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- METADATA FOUND ---\n",
      "{\n",
      "  \"court\": \"IN THE SUPREME COURT OF INDIA\",\n",
      "  \"case_number\": \"NO. 354 OF 2019\",\n",
      "  \"petitioner\": \"Not Found\",\n",
      "  \"respondent\": \"Not Found\",\n",
      "  \"judgment_date\": \"12.12.2018\"\n",
      "}\n",
      "\n",
      "--- SECTIONS FOUND ---\n",
      "{\n",
      "  \"conclusion\": \"orders, \\nand \\nthe \\nsaid \\napplication \\nwill \\nbe \\nconsidered/decided on its own merits without \\nbeing influenced by any of the observations \\nmade by us. \\n21. Pending application(s), if any, shall stand disposed of. \\n \\n \\n \\n\\u2026\\u2026..\\u2026\\u2026\\u2026\\u2026\\u2026\\u2026\\u2026\\u2026\\u2026J. \\n(VIKRAM NATH) \\n \\n \\n \\n\\u2026\\u2026..\\u2026\\u2026\\u2026\\u2026\\u2026\\u2026\\u2026\\u2026\\u2026J. \\n(PRASANNA B. VARALE) \\n \\n \\nNEW DELHI \\nFEBRUARY  28, 2025\",\n",
      "  \"facts\": \"the factual matrix, including \\nthe allotment of government land and its subsequent \\nuse by the allottees. The appellant contended that the \\nalleged acts of omission or commission were done in \\ndischarge of his duties in the quasi-judicial \\nproceedings and did not amount to criminal \\nmisconduct or breach of trust as contemplated under \\nthe penal provisions invoked.        \\n7. \\nThe High Court, after perusing the FIR and the \\nsupporting materials, observed that the allegations \\npertained to a serious matter involving government \\nland and its misuse, which prima facie disclosed \\ncommission of cognizable offences under the IPC. The \\nHigh Court noted that the disputed facts, such as the \\ncultivation of the land by the original allottees and \\nthe subsequent alleged violations, required thorough \\ninvestigation and could not be adjudicated at the \\npreliminary stage. It was held that quashing the FIR \\nat the nascent stage would amount to preemptively \\nstifling a legitimate investigation into potential abuse \\nof public resources. It was further observed that from \\na bare reading of the\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --- INTERACTIVE TESTING CELL ---\n",
    "# Pick one file from your 'judgments' folder to test with\n",
    "test_file_name = 'j1.pdf' # <--- CHANGE THIS to a real file name from your folder\n",
    "\n",
    "# Extract text from this single file\n",
    "test_file_path = os.path.join(INPUT_FOLDER, test_file_name)\n",
    "full_text = \"\"\n",
    "with fitz.open(test_file_path) as doc:\n",
    "    for page in doc:\n",
    "        full_text += page.get_text()\n",
    "\n",
    "# Test the metadata function\n",
    "metadata_result = extract_metadata(full_text)\n",
    "print(\"--- METADATA FOUND ---\")\n",
    "print(json.dumps(metadata_result, indent=2))\n",
    "\n",
    "# Test the section extraction function\n",
    "sections_result = extract_sections(full_text)\n",
    "print(\"\\n--- SECTIONS FOUND ---\")\n",
    "print(json.dumps(sections_result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf001611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting judgment processing pipeline...\n",
      "Created output folder: structured_output\n",
      "\n",
      "Processing file: j1.pdf...\n",
      "  -> Successfully saved to structured_output\\j1.json\n",
      "\n",
      "Processing file: j2.pdf...\n",
      "  -> Successfully saved to structured_output\\j2.json\n",
      "\n",
      "Processing file: j3.pdf...\n",
      "  -> Successfully saved to structured_output\\j3.json\n",
      "\n",
      "Processing file: j4.pdf...\n",
      "  -> Successfully saved to structured_output\\j4.json\n",
      "\n",
      "Processing file: j5.pdf...\n",
      "  -> Successfully saved to structured_output\\j5.json\n",
      "\n",
      "Pipeline finished.\n"
     ]
    }
   ],
   "source": [
    "# --- MAIN SCRIPT LOGIC ---\n",
    "\n",
    "print(\"Starting judgment processing pipeline...\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "    print(f\"Created output folder: {OUTPUT_FOLDER}\")\n",
    "\n",
    "pdf_files = [f for f in os.listdir(INPUT_FOLDER) if f.endswith('.pdf')]\n",
    "\n",
    "if not pdf_files:\n",
    "    print(f\"No PDF files found in '{INPUT_FOLDER}'.\")\n",
    "else:\n",
    "    for pdf_file_name in pdf_files:\n",
    "        try:\n",
    "            input_path = os.path.join(INPUT_FOLDER, pdf_file_name)\n",
    "            print(f\"\\nProcessing file: {pdf_file_name}...\")\n",
    "            full_text = \"\"\n",
    "            with fitz.open(input_path) as doc:\n",
    "                for page in doc:\n",
    "                    full_text += page.get_text()\n",
    "            if not full_text.strip():\n",
    "                print(f\"  -> WARNING: No text extracted. Might be a scanned image.\")\n",
    "                continue\n",
    "            \n",
    "            metadata = extract_metadata(full_text)\n",
    "            sections = extract_sections(full_text)\n",
    "            \n",
    "            final_output = {\n",
    "                \"source_file\": pdf_file_name,\n",
    "                \"metadata\": metadata,\n",
    "                \"extracted_sections\": sections\n",
    "            }\n",
    "            \n",
    "            output_file_name = pdf_file_name.replace('.pdf', '.json')\n",
    "            output_path = os.path.join(OUTPUT_FOLDER, output_file_name)\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(final_output, f, indent=4, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"  -> Successfully saved to {output_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  -> ERROR processing {pdf_file_name}: {e}\")\n",
    "\n",
    "    print(\"\\nPipeline finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473b830f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
